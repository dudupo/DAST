\title{Graphs  - Recitation 9} 
\input{../texlib/head}
\usetikzlibrary{positioning, arrows}
\tikzset{main node/.style={circle,draw,minimum size=0.8cm,inner sep=0pt},}
\tikzset{edge/.style = {->,> = latex'}}

\iffalse
\newtheorem{prop}{Proposition}
\newtheorem{ex}{Exercise}
\newtheorem{sol}{Solution}
\newtheorem{theorem}{Theorem} \newtheorem{thm}{Theorem}[section]
\newtheorem{conj}[thm]{Conjecture} \newtheorem{lemma}[thm]{Lemma}
\newtheorem{corollary}[thm]{Corollary} \newtheorem{claim}[thm]{Claim}
\newtheorem{proposition}[thm]{Proposition}
\newtheorem{definition}{Definition} \newtheorem{remark}{Remark}
   
\pagestyle{empty}

\setlength{\textwidth}{6.5in}
\setlength{\evensidemargin}{0.0in}
\setlength{\oddsidemargin}{0.0in}
\setlength{\topmargin}{-0.25in}
\setlength{\textheight}{9.0in}
\setlength{\baselineskip}{1.3\baselineskip}
\setlength{\parindent}{.0in}
\fi
\tikzset{
node of list/.style = { 
             draw, 
             fill=orange!20, 
             minimum height=6mm, 
             minimum width=6mm,
             node distance=6mm
   },
link/.style = {
     -stealth,
     shorten >=1pt
     },
array element/.style = {
    draw, fill=white,
    minimum width = 6mm,
    minimum height = 10mm
  }
}

\def\LinkedList#1{%
  \foreach \element in \list {
     \node[node of list, right = of aux, name=ele] {\element};
     \draw[link] (aux) -- (ele);
     \coordinate (aux) at (ele.east);
  } 
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\vspace{0.2in}

\section{Graphs}
This is an important section, as you'll see graphs A LOT in this course and in the courses to follow. 

\subsection{Definitions, Examples, and Basics}

\begin{figure}[h]
\begin{subfigure}[b]{0.65\textwidth}
\begin{definition}
A \textbf{non-directed graph} $G$ is a pair of two sets - $G=(V, E)$ - $V$ being a set of vertices and $E$ being a set of couples of vertices, which represent edges ("links") between vertices.
\end{definition}

\textbf{Example}: $G= (\{1,2,3,4\},\ \{\{1,2\}, \{1,3\}, \{3,4\}\})$ is the following graph:\\ 
\end{subfigure}
\begin{subfigure}[b]{0.05\textwidth}
  \
\end{subfigure}
  \begin{subfigure}[b]{0.25\textwidth}
    \begin{tikzpicture}
\node[main node](1){$1$};
\node[main node](2)[below = 1cm of 1]{$2$};
\node[main node](3)[right = 1cm of 1]{$3$};
\node[main node](4)[below = 1cm of 3]{$4$};

\path[draw, thick]
(1) edge node {} (2)
(1) edge node {} (3)
(3) edge node {} (4);
\end{tikzpicture}
\end{subfigure}
\end{figure}
\begin{figure}[h]
\begin{subfigure}[b]{0.65\textwidth}
\begin{definition}
A \textbf{directed graph} $G$ is a pair of two sets - $G=(V, E)$ - $V$ being a set of vertices and $E\subseteq V\times V$ being a set of directed edges ("arrows") between vertices.
\end{definition}
\textbf{Example}: $G=(\{1,2,3,4\},\ \{(1, 2), (1, 4), (4, 1), (4,3)\})$ is the following graph (note that it has arrows): \\ 
\end{subfigure}
\begin{subfigure}[b]{0.05\textwidth}
  \
\end{subfigure}
  \begin{subfigure}[b]{0.25\textwidth}
    \begin{tikzpicture}
\node[main node](1){$1$};
\node[main node](2)[below = 1cm of 1]{$2$};
\node[main node](3)[right = 1cm of 1]{$3$};
\node[main node](4)[below = 1cm of 3]{$4$};

\draw[edge] (1) to (2);
\draw[edge] (1) to (4);
\draw[edge] (4) to (1);
\draw[edge] (4) to (3);
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{definition}
  A \textbf{weighted graph} composed by a graph $G=\left( V,E \right)$ (either non-directed or directed) and a weight function $w : E \rightarrow \mathbb{R}$. Usually (but not necessary), we will think about the quantity $w(e)$, where $e \in E$, as the length of the edge.  
\end{definition}

Now that we see graphs with our eyes, we can imagine all sorts of uses for them... For example, they can represent the structure of the connections between friends on Facebook, or they can even represent which rooms in your house have doors between them.

\begin{remark}
Note that directed graphs are a \textbf{generalization} of non-directed graphs, in the sense that every non-directed graph can be represented as a directed graph. Simply take every non-directed edge $\{v,u\}$ and turn it into two directed edges $(v,u), (u,v)$. 
\end{remark}

\begin{remark}
Note that most of the data structures we discussed so far - Stack, Queue, Heap, BST - can all be implemented using graphs.
\end{remark}

Now let's define some things in graphs:

\begin{definition} (Path, circle, degree)
\begin{enumerate} 
\item A \textbf{simple path} in the graph $G$ is a series of unique vertices (that is, no vertex appears twice in the series) $v_1, v_2, ..., v_n$ that are connected with edges in that order. 
\item A \textbf{simple circle} in the graph $G$ is a simple path such that $v_1 = v_n$. 
\item The \textbf{distance} between two vertices $v,u\in V$ is the length of the shortest path between them ($\infty$ if there is no such path).
\end{enumerate}
\end{definition}

\begin{remark}
Note that for all $u,v,w\in V$ the triangle inequality holds regarding path lengths. That is:
$$dist(u,w)\leq dist(u,v) + dist(v, w)$$
\end{remark}

\begin{definition} (connectivity)
\begin{enumerate}
  \item Let $ G =\left( V,E \right)$ be a non-directed graph. A \textbf{connected component} of $G$ is a subset $U \subseteq V$ of maximal size in which there exists a path between every two vertices. 
\item A non-directed graph $G$ is said to be a \textbf{connected} graph if it only has one connected component.
\item Let $ G = \left(V, E\right)$ be a directed graph. A \textbf{strongly connected component} of $G$ is a subset $U \subseteq V$ of maximal size in which for any pair of vertices $u,v \in U$ there exist both directed path from $u$ to $v$ and a directed path form $v$ to $u$.   
\end{enumerate}
\end{definition}
%\begin{figure}[h]
  %\begin{subfigure}[b]{0.4\textwidth} 
%An \textbf{example} of a non-connected graph: \\ \\ \\  \\
%\end{subfigure}
%\begin{subfigure}[b]{0.05\textwidth}
  %\
%\end{subfigure}
%\begin{subfigure}[b]{0.25\textwidth}
%\begin{tikzpicture}
%\node[main node](1){$1$};
%\node[main node](2)[below = 1cm of 1]{$2$};
%\node[main node](3)[right = 1cm of 1]{$3$};
%\node[main node](4)[below = 1cm of 3]{$4$};
%
%\draw[edge] (1) to (2);
%\draw[edge] (3) to (4);
%\end{tikzpicture}
%\end{subfigure}
%\end{figure}

\begin{prop}
Let $G=(V,E)$ be some graph. If $G$ is connected, then $|E| \geq |V|-1$
\end{prop}

\begin{proof}
We will perform the following cool process: Let $\{e_1,...,e_m\}$ be an enumeration of $E$, and let $G_0=(V,\emptyset)$. We will build the graphs $G_1, G_2,... G_m=G$ by adding edges one by one. Formally, we define - 
$$\forall i\in[m]\ \ G_i=(V,\{e_1,...,e_i\})$$
$G_0$ has exactly $|V|$ connected components, as it has no edges at all. Then $G_1$ has $|V|-1$. From there on, any edges do one of the following:
\begin{enumerate}
    \item Keeps the number of connected components the same (the edge closes a cycle)
    '\item Lowers the number of connected components by $1$ (the edges does not close a cycle)
\end{enumerate}

So in general, the number of connected components of $G_i$ is $\geq |V|-i$. 
Now, if $G_m=G$ is connected, it has just one connected component! This means:
$$1 \geq |V| - |E|\ \implies \ |E|\geq|V|-1$$

\end{proof}


\subsection{Graph Representation}

Okay, so now we know what graphs are. But how can we represent them in a computer? There are two main options. The first one is by \textbf{array of adjacency lists}. Given some graph $G$, every slot in the array will contain a linked list. Each linked list will represent a list of some node's neighbors. The second option is to store edges in an \textbf{adjacency matrix}, a $ |V| \times |V| $ binary matrix in which the $v,u$-cell equals $1$ if there is an edge connecting $u$ to $v$. That matrix is denoted by $A_{G}$ in the example below. Note that the running time analysis might depend on the underline representation.     

\textbf{Question.} What is the memory cost of each of the representations? Note that while holding an adjacency matrix requires storing $|V|^2$ bits regardless of the size of $E$, Maintaining the edges by adjacency lists costs linear memory at the number of edges and, therefore, only $ \Theta \left(  |V| + |E| \right) $ bits. 

\paragraph{Example.} Consider the following directed graph:
\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.25\textwidth}
    \begin{tikzpicture}
      \node[main node](1){$1$};
      \node[main node](2)[below = 1cm of 1]{$2$};
      \node[main node](3)[right = 1cm of 1]{$3$};
      \node[main node](4)[below = 1cm of 3]{$4$};

      \draw[edge] (1) to (2);
      \draw[edge] (1) to (4);
      \draw[edge] (4) to (1);
      \draw[edge] (4) to (3);
      \draw[edge] (1) to (3);
      \draw[edge] (3) to (1);
    \end{tikzpicture}  
    \\ \\  
  \end{subfigure} 
  \begin{subfigure}[b]{0.49\textwidth}
    \begin{tikzpicture}
      \foreach \index/\list in {1/{2,3,4,null}, 2/{null}, 3/{1, null}, 4/{1, 3, null}} {
	\node[array element] (aux) at (0,-\index) {\index};
	\LinkedList{\list}
      }
    \end{tikzpicture}  
  \end{subfigure}
  \caption{ Persenting $G$ by array of adjacency lists.  }
\end{figure}

%Its representation will be: \\ \\

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.25\textwidth}
        \begin{tikzpicture}
\node[main node](1){$1$};
\node[main node](2)[below = 1cm of 1]{$2$};
\node[main node](3)[right = 1cm of 1]{$3$};
\node[main node](4)[below = 1cm of 3]{$4$};

\draw[edge] (1) to (2);
\draw[edge] (1) to (4);
\draw[edge] (4) to (1);
\draw[edge] (4) to (3);
\draw[edge] (1) to (3);
\draw[edge] (3) to (1);
\end{tikzpicture} \\ 
  \end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}       
  \begin{tikzpicture}
    \node (1) at (0,0) { };
    \node  (2) at (1,1.7) { $ A_{G} = 
	  \begin{bmatrix}
	0 & 1 & 1 & 1\\
	0 & 0 & 0 & 0\\
	1 & 0 & 0 & 0\\
	1 & 0 & 1 & 0
	\end{bmatrix}
      $ };
      \end{tikzpicture}
\end{subfigure}
\caption{ Presenting $G$ by adjacency matrix. }
\end{figure}

\subsection{Breadth First Search (BFS)}

One natural thing we might want to do is to travel around inside a graph. That is, we would like to visit all of the vertices in a graph in some order that relates to the edges. 
Breadth-first search constructs a breadth-first tree, initially containing only its root, which is the source vertex $s$. Whenever the search discovers a white vertex $v$ in the course of scanning the adjacency list of a gray vertex $u$, the vertex $v$ and the edge ($u$, $v$) are added to the tree. We say that $u$ is the predecessor or parent of $v$ in the breadth-first tree. Since every vertex reachable from $s$ is discovered at most once, each vertex reachable from $s$ has exactly one parent. (There is one exception: because $s$ is the root of the breadth-first tree, it has no parent.) Ancestor and descendant relationships in the breadth-first tree are defined relative to the root $s$ as usual: if $u$ is on the simple path in the tree from the root $s$ to vertex $v$, then $u$ is an ancestor of $v$, and $v$ is a descendant of $u$.
The breadth-first-search procedure BFS on the following page assumes that the graph $G = (V, E)$ is represented using adjacency lists. It denotes the queue by $Q$, and it attaches three additional attributes to each vertex $v$ in the graph:

\begin{enumerate}
    \item $v$.visited is a boolean flag which indicate wheter $v$ was allready visited.
    \item $\pi(v)$ is $v$’s predecessor in the breadth-first tree. If $v$ has no predecessor because it is the source vertex or is undiscovered, then $\pi(v)$ is None/NULL.
\end{enumerate}

\begin{algbox}{BFS($G, s$)}
  \begin{algorithm}[H]
    \For {$v\in V$}{
	 $v.visited \leftarrow $ False 
     }
  $s.dist\leftarrow 0$ \\
 $Q\leftarrow$ new Queue \\ 
 $Q$.Enqueue($s$) \\
 $s$.visited $\leftarrow$ True \\
 \While {$Q$ is not empty} {
 $u\leftarrow Q$.Dequeue() \\
	\For {neighbor $w$ of $u$} {
	\If {$w$.visited is False}{
		 $w$.visited$\leftarrow$ True \\
		 $\pi(w) \leftarrow u $ \\
		 $Q$.Enqueue($w$)

	      }
	}
      }
  \end{algorithm}
\end{algbox}

\underline{Correctness}: The example should be enough to explain the correctness. A concrete proof can be found in the book, page 597.

\underline{Runtime}: We can analyse the runtime line-by-line:
\begin{itemize}
\item Lines 1-2: $|V|$ operations, all in $O(1)$ runtime, for a total of $O(|V|)$.
\item Lines 3-6: $O(1)$
\item Lines 7-8: First we need to understand the number of times the $while$ loop iterates. We can see that every vertex can only enter the queue ONCE (since it is then tagged as "visited"), and therefore it runs $\leq |V|$ times. All operations are $O(1)$, and we get a total of $O(|V|)$. 
\item Lines 9-13: Next, we want to understand the number of times this $for$ loop iterates. 
The for loop starts iterating once per vertex, and then the number of its iterations is the same as the number of neighbors that this vertex has. Thus, it runs $O(|E|)$ times.
\end{itemize}
So all in all we get a runtime of $O(|V|+|E|)$

\subsection{Usage of BFS}
Now we have a way to travel through a graph using the edges. How else can we use it?\\ \\ 
\textbf{Exercise}: Present and analyse an algorithm $CC(G)$ which receives some undirected graph $G$ and outputs the number of connected components in $G$ in $O(|V|+|E|)$. \\

\textbf{Solution}: Consider the following algorithm: (Now read the algorithm, it may be in the next page because LaTeX is dumb...)
\begin{algbox}{CC($G$)}
  \begin{algorithm}[H]
     count $\leftarrow 0$\\
     \For {$v\in V$ }{
	\If {$v$.visited = False} {
	  count$\leftarrow$count$+1$ \\
	  BFS($G, v$)
	}
      }
	\Return count
  \end{algorithm}
\end{algbox}

\subsection{Depth First Search (DFS)}
As its name implies, depth-first search searches "deeper" in the graph whenever possible. Depth-first search explores edges out of the most recently discovered vertex $v$ that still has unexplored edges leaving it. Once all of $ v$'s edges have been explored, the search "backtracks" to explore edges leaving the vertex from which $v$ was discovered. This process continues until all vertices that are reachable from the original source vertex have been discovered. If any undiscovered vertices remain, then depth-first search selects one of them as a new source, repeating the search from that source. The algorithm repeats this entire process until it has discovered every vertex.

\begin{algbox}{DFS($G$)}
  \begin{algorithm}[H]
   \bf{DFS}( $G$): \\
    \For {$v\in V$}{
 	$vi$.visited $\leftarrow False$
    }
    time $ \leftarrow 1 $
    \For {$v\in V$}{
      \If { not $v$.visited } {
	$\pi \left( v \right) v \leftarrow $ null \\ 
	Explore( $G,v$ ) 
     } 
   }

  \end{algorithm}

  \begin{algorithm}[H]
    \bf{Explore}($G,v$): \\
    \For {$\left( v,u \right) \in E  $}{
      Previsit($v$)
      \If { not $u$.visited } {
	$ \pi \left( u \right) \leftarrow v $ \\ 
	Explore( $G, u$ ) 
      }
      Postvisit($v$)
    }
  \end{algorithm}
  \begin{algorithm}[H]
    \bf{Previsit}($v$): \\
    pre($v$) $\leftarrow $ time \\
    time $\leftarrow$ time $+1$
  \end{algorithm}
 \begin{algorithm}[H]
   \bf{Postvisit} ($v$): \\ 
    post($v$) $\leftarrow $ time \\
    time $\leftarrow$ time $+1$
  \end{algorithm}


\end{algbox}
\paragraph{Properties of depth-first search.} Depth-first search yields valuable information about the structure of a graph. Perhaps the most basic property of depth-first search is that the predecessor subgraph $G_{\pi}$ does indeed form a forest of trees since the structure of the depth-first trees exactly mirrors the structure of recursive calls of explore-function. That is, $u$ = $\pi\left( v \right)$ if and only if explore($G, v$) was called during a search of $ u$'s adjacency list. Additionally, vertex $v$ is a descendant of vertex $u$ in the depth-first forest if and only if $v$ is discovered during the time in which $u$ is gray.
Another important property of depth-first search is that discovery and finish times have a parenthesis structure. If the explore procedure were to print a left parenthesis "$(u$" when it discovers vertex $u$ and to print a right parenthesis r``$u)$" when it finishes $u$, then the printed expression would be well-formed in the sense that the parentheses are properly nested.

The following theorem provides another way to characterize the parenthesis structure.

\paragraph{Parenthesis theorem}
In any depth-first search of a (directed or undirected) graph $G = (V, E)$, for any two vertices $u$ and $v$, exactly one of the following three conditions holds:

\begin{enumerate}
  \item the intervals [pre($u$), post($u$)] and [pre($v$), post($v$)] are entirely disjoint, and neither $u$ nor $v$ is a descendant of the other in the depth-first forest.
  \item the interval [pre($u$), post($u$)] is contained entirely within the interval [pre($v$), post($v$)], and $u$ is a descendant of $v$ in a depth-first tree, or
  \item the interval [pre($v$), post($v$)] is contained entirely within the interval [pre($u$), post($u$)], and $v$ is a descendant of $u$ in a depth-first tree.
  \end{enumerate}

  \paragraph{Proof.} We begin with the case in which pre($u$) $<$ pre($v$). We consider two subcases, according to whether pre($v$) $<$ post($u$). The first subcase occurs when pre($v$) $<$ post($u$), so that $v$ was discovered while $u$ was still gray, which implies that $v$ is a descendant of $u$. Moreover, since $v$ was discovered after $u$, all of its outgoing edges are explored, and $v$ is finished before the search returns to and finishes $u$. In this case, therefore, the interval [pre($v$), post($v$)] is entirely contained within the interval [pre($u$), post($u$)]. In the other subcase, post($u$) $<$ pre($v$), and by defintion, pre($u$) $<$ post($u$) $<$ pre(v) $<$ post($v$), and thus the intervals [pre($u$), post($u$)] and [pre($v$), post($v$)] are disjoint. Because the intervals are disjoint, neither vertex was discovered while the other was gray, and so neither vertex is a descendant of the other.



\paragraph{  Corollary. Nesting of descendants' intervals.}
  Vertex $v$ is a proper descendant of vertex $u$ in the depth-first forest for a (directed or undirected) graph $G$ if and only if pre($u$) $<$ pre($v$) $<$ post($v$) $<$ post($u$).

  \paragraph{Problem. Two Chess Pieces.}
  $Cirno_9baka$ has a tree with n nodes. He is willing to share it with you, which means you can operate on it.

Initially, there are two chess pieces on the node 1 of the tree. In one step, you can choose any piece, and move it to the neighboring node. You are also given an integer d. You need to ensure that the distance between the two pieces doesn't ever exceed d.

Each of these two pieces has a sequence of nodes which they need to pass in any order, and eventually, they have to return to the root. As a curious boy, he wants to know the minimum steps you need to take.


\input{../texlib/tail}

