
\input{../texlib/head}
\newcommand{\image}{\text{ Im } }


\begin{document}
\ifdefined\BOOK
\else
\setcounter{chapter}{6}
\fi
\chapter{Probability.} 

\section{ Probability Spaces. }

\begin{definition}
  A probability space is defined by a tuple $(\Omega,P)$, where:
  \begin{enumerate} 
    \item $\Omega$ is a set, called the sample space. Any element $\omega\in \Omega$ is an atomic event. Conceptually, we think of atomic events as possible outcomes of our experiment. Any subset $A \subset \Omega$ is an event. 
    \item $P$, called the probability function, is a function that assigns a number in $[0,1]$ to any event, denoted as $P : 2^\Omega \rightarrow [0,1]$, and satisfies:
      \begin{enumerate}
        \item For any event $A \subset \Omega$, $P(A) = \sum_{\omega\in A}P(\omega)$. 
        \item Normalization over the atomic events to $1$, which means $\sum_{\omega\in\Omega}P(\omega)~=~1$.
      \end{enumerate}
  \end{enumerate}
\end{definition}
\begin{example}
  Consider a dice rolling, where each of the faces is indexed by $1,2,3,4,5,6$ and has an equal chance of being rolled. Therefore, our atomic events are associated with the rolling result, and $P$ is defined as $P(\omega) = \frac{1}{6}$ for any such atomic event.
  An example of an event can be $A=$ ''the dice falls on an even number''. The probability of this outcome is:
  \begin{equation*}
    \begin{split}
      P(A)= \sum_{\omega\in A}{ P(\omega) } = P(\{2\}) + P(\{4\}) + P(\{6\}) = 3\cdot \frac{1}{6} = \frac{1}{2} 
    \end{split}
  \end{equation*}
\end{example}

%\begin{claim}
%Probability function  satisfies the following properties:
%\begin{enumerate}
%  \item $P(\emptyset) = 0$.
%  \item Monotonic, If $A \subset B \subset \Omega$ then $P(A) \le P(B)$.
%  \item Union Bound, $P(A \cup B) \le P(A) + P(B)$.
%  \item Additivity for disjointness events. If $A\cap B = \emptyset$ then $P(A \cup B) = P(A) + P(B)$.
%  \item Denote by $\bar{A}$ the complementary event of $A$, which means $A\cup\bar{A} = \Omega$. Then, $P(\bar{A}) = 1 - P(A)$.
%\end{enumerate}
%\end{claim}
%
\begin{claim}
The probability function satisfies the following properties:
\begin{enumerate}
  \item $P(\emptyset) = 0$.
  \item Monotonicity: If $A \subset B \subset \Omega$, then $P(A) \le P(B)$.
  \item Union Bound: $P(A \cup B) \le P(A) + P(B)$.
  \item Additivity for disjoint events: If $A\cap B = \emptyset$, then $P(A \cup B) = P(A) + P(B)$.
  \item Complementarity: Denote by $\bar{A}$ the complementary event of $A$, which means $A\cup\bar{A} = \Omega$. Then, $P(\bar{A}) = 1 - P(A)$.
\end{enumerate}
\end{claim}

\begin{example}
  Let's proof the additivity of disjointness property. Let $A,B$ disjointness events, so $A \cap B = \emptyset$ then 
  
  \begin{equation*}
    \begin{split}
      P(A\cup B) &= \sum_{w \in A \cup B}P(w) \\ 
      &= \overbrace{\sum_{w \in A, w \notin{B}}P(w)}^{P(A)} + \overbrace{\sum_{w \in B, w \notin A}P(w)}^{P(B)}  +\overbrace{ \sum_{w \in A, w \in  B}P(w) }^{ 0 } \\ 
      &= P(A) + P(B) 
    \end{split}
  \end{equation*}
\end{example}

\begin{definition}
  Let $(\Omega,P)$ be a probability space. A random variable $X$ on $(\Omega,P)$ is a function $X : \Omega \rightarrow \mathbb{R}$. An indicator, is a random variable defined by an event $A \subset \Omega$ as follows   
  \begin{equation*}
    X(\omega) = \begin{cases}
      1 & \omega \in A \\
      0 & \omega \notin A
    \end{cases}
  \end{equation*}
Sometimes, we will use the notation $\{ X = x \}$ to denote the event $A$ such: 
\begin{equation*}
  \begin{split}
    A = \{ \omega : X(\omega) = x \} := \{ X = x \} 
  \end{split}
\end{equation*}
\end{definition}
\begin{example} \label{example:twodic} Consider rolling a pair of dice. Denote by $X : [6]\times [6] \rightarrow [6] $ the random variable that is set to be the result of the first roll. Let $Y$ be defined in almost the same way, but setting the result of the second die. Namely, if we denote by $\{(i,j)\}$ the atomic event associated with sample $i$ on the first die and $j$ on the second die, then:
  \begin{equation*}
    \begin{split}
      X(\{i,j\}) &= i \\ 
      Y(\{i,j\}) &= j  
    \end{split}
  \end{equation*}
  In addition, one can define the random variable $z$ as the sum, $Z = X+Y$. Since the sum is also a function from $\Omega$ to $\mathbb{R}$, $Z$ is also a random variable. An example of an indicator could be $W$, which gets $1$ if $Z \in \{2, 7, 8\}$.
\end{example}


\begin{example}
  Let $X$ be an indicator of event $A$. Then $1 - X$ is the indicator of $\bar{A}$.
\begin{equation*}
   1 -  X(\omega) = \begin{cases}
     0 & \omega \in A \Leftrightarrow  \omega \notin \bar{A} \\
      1 & \omega \notin A\Leftrightarrow  \omega \in \bar{A}
    \end{cases}
  \end{equation*}

\end{example}

\begin{definition}
  We will say that two events $A,B$ are independent if:
\begin{equation*}
    \begin{split}
      P(A \cap B) &= P(A) \cdot P (B) %\Leftrightarrow \\ 
    \end{split}
  \end{equation*}
  Similarly we will say that random variables $X,Y : \Omega \rightarrow \mathbb{R}$  are independent if for any $x\in \image X$ and $y \in \image Y$:   
  \begin{equation*}
    \begin{split}
      P(X = x \cap Y = y) &= P(X = x) \cdot P (Y = y) %\Leftrightarrow \\ 
    \end{split}
  \end{equation*}
  \end{definition}
  \begin{example}
    $X,Y$ defined in \Cref{example:twodic} are independent. 
    \begin{equation*}
      \begin{split}
        P(\{X = i\} \cap \{Y = j\} ) &= \sum_{i^{\prime} = i \text{ and } j^{\prime}=j }P(\{(i^{\prime}, j^{\prime})\}) = P(\{ (i,j) \} ) \\ 
        &= \frac{1}{36} = \frac{1}{6} \cdot \frac{1}{6}  = P(X = i)P(Y = j)
      \end{split}
    \end{equation*}
  \end{example}

  \begin{example}
    Let $A$ and $B$ be independent events. Then, $\bar{A}$ and $B$ are also independent events, since:
    \begin{equation*}
      \begin{split}
    P(B) &= P(B \cap \Omega) = P(B \cap (A \cup \bar{A})) = P((B \cap A) \cup (B \cap \bar{A}))\\
    &= P(B \cap A) + P(B \cap \bar{A}) = P(B)P(A) +    P(B \cap \bar{A} ) \\
    \Rightarrow  P(B \cap \bar{A} ) & = P(B)(1 - P(A)) = P(B)P(\bar{A})
      \end{split}
    \end{equation*}
  \end{example}

  \begin{example}
    Let $X$ and $Y$ be indicators of independent events $A$ and $B$. Then $P(X\cdot Y = 1) = P(X = 1)\cdot P(Y = 1)$. The proof is left as an exercise.
  \end{example}

  \section{ Throwing Keys to Cells. }  
  \begin{example} Imagine that following experiment, we have $m$ cells and $n$ keys (balls, numbers, or your favorite object type). We throw each of the keys independently into the cells. The cells are identical, so the probability of hitting any of them is the same, $1/m$. We would like to analyze how the capacity of the cells is distributed.
    \begin{enumerate}
      \item What is the probability that the first and the second keys will be thrown to the first cell? What is the probability that the first and the second keys will be thrown to the same cell? 
      \item What is the probability that in the first cell there is exactly one key? 
    \end{enumerate}
    Let us define the indicator $X_{i}^{j}$ which indicate that the $j$th key fallen into the $i$th cell. 
    \begin{enumerate}
      \item So first we been asked whether $X_{1}^{1}\cdot  X_{1}^{2} = 1$, Since this happens only if both $X_{1}^{1} = 1$, $X_{1}^{2} = 1$ then by independently we have that: 
        \begin{equation*}
          \begin{split}
            P({X_{1}^{1}\cdot  X_{1}^{2} = 1}) &= P(X_{1}^{1} = 1 \cap  X_{1}^{2} = 1) \\
            & = P(X_{1}^{1} = 1 ) \cdot P( X_{1}^{2} = 1) =\frac{1}{m^2}
          \end{split}
        \end{equation*} Now, to answer if the first and second keys fall into the same cell, we need to check if there exists an $i$ such that $X_{i}^{1}\cdot X_{i}^{2} = 1$. Observes that for any different $i$ and $i^{\prime}$, the $X_{i}^{j}$ and $X_{i^{\prime}}^{j}$ are indicators of disjoint events. This is because $j$ cannot be in both the $i$ and $i^{\prime}$ cells. Therefore, $X_{i}^{1}\cdot X_{i}^{2}$ and $X_{i^{\prime}}^{1}\cdot X_{i^{\prime}}^{2}$ are also indicators of disjoint events. Thus: 
        \begin{equation*}
          \begin{split}
            P(\exists i : X_{i}^1 \cdot X_{i}^{2} = 1) &= P( \bigcup_{i} X_{i}^1 \cdot X_{i}^{2} = 1) \\
            &= \sum_{i}{P( X_{i}^1 \cdot X_{i}^{2} = 1)} = m\cdot \frac{1}{m^{2}} = \frac{1}{m}
          \end{split}
        \end{equation*} 
        We are basically done. However, we want to present the same calculation in a different notation that will be useful for computing expectations later on. Note that the random variable that counts ''how many'' cells both the first and the second fall into is $\sum_{i}{X_{i}^{1}\cdot X_{i}^{2} }$. In other words, the sum can be either $0$ if the keys fall into different cells, or $1$ if they both fall into the same cell.
      \item The event that only the $j$th key falls into the first cell matches to 
        \begin{equation*}
          \begin{split}
            \left\{ X_{1}^{j}\prod_{j\neq j^{\prime}}\left( 1 - X_{1}^{j^{\prime}} \right) = 1 \right\}
          \end{split}
        \end{equation*}
        Therefore, due to the disjointness of $1-X_{1}^{j^{\prime}}$ and $X_{1}^{j^{\prime}}$, the indicator for the first cell containing exactly one key is:
        \begin{equation*}
          \begin{split}
            \left\{ \sum_{j}{X_{1}^{j}\prod_{j\neq j^{\prime}}\left( 1 - X_{1}^{j^{\prime}} \right)} = 1  \right\}
          \end{split}
        \end{equation*} 
        Since the terms in the sum are disjoint and the products are products of independent indicators, we have:
        \begin{equation*}
          \begin{split}
            & P\left(\sum_{j}{X_{1}^{j}\prod_{j\neq j^{\prime}}\left( 1 - X_{1}^{j^{\prime}} \right)} = 1 \right) = \sum_{j}{ P\left( X_{1}^{j}\prod_{j\neq j^{\prime}}\left( 1 - X_{1}^{j^{\prime}} \right) = 1 \right)} \\
            = \ & m \cdot \frac{1}{m}\left( 1 - \frac{1}{m} \right)^{n-1} =  \left( 1 - \frac{1}{m} \right)^{n-1}
          \end{split}
        \end{equation*}
    \end{enumerate}
  \end{example}

\begin{definition}
  Let $X : \Omega\rightarrow \mathbb{R}$ be a random variable, the expectation of $X$ is 
  \begin{equation*}
    \begin{split}
      \expp{X} = \sum_{\omega\in \Omega}{X(\omega)P(\omega)} = \sum_{x \in \image X}{ x P(X = x)} 
    \end{split}
  \end{equation*} Observes that if $P$ is distributed uniformly, then the expectation of $X$ is just the arithmetic mean: \begin{equation*}
    \begin{split}
      \expp{X} = \sum_{\omega\in \Omega}{X(\omega)P(\omega)} =  \frac{1}{|\Omega|}\sum_{\omega\in \Omega}{X(\omega)}  
    \end{split}
  \end{equation*}
\end{definition}

\begin{claim}
   The expectation satisfies the following properties:
   \begin{enumerate}
     \item Monotonic, If $X \le Y$ (for any $\omega \in \Omega$) then $\expp{X} \le \expp{Y}$.   
     \item Linearity, for $a,b \in \mathbb{R}$ it holds that $\expp{aX + by} = a\expp{X} + b \expp{Y}$.   
     \item Independently, if $X,Y$ are independent, then $\expp{X\cdot Y} = \expp{X}\cdot \expp{Y}$.  
     \item For any constant $a \in \mathbb{R}$ we have that $\expp{a} = a$. 
   \end{enumerate}
\end{claim}

\begin{proof} 
  \begin{enumerate}
\item Monotonic, if $X \le Y$ then : 
  \begin{equation*}
    \begin{split}
      \expp{X} = \sum_{\omega\in \Omega}{X(\omega)P(\omega)} \le  \sum_{\omega\in \Omega}{Y(\omega)P(\omega)} = \expp{Y}
    \end{split}
  \end{equation*}
\item Linearity,
  \begin{equation*}
    \begin{split}    
      \expp{a X + b Y} &=  \sum_{\omega\in \Omega}{ \left( aX(\omega) + bY(\omega) \right) P(\omega)} \\ 
      &=a\sum_{\omega\in \Omega}{  X(\omega)  P(\omega) } + b \sum_{\omega\in \Omega}{   Y(\omega)  P(\omega)}
    \end{split}
  \end{equation*}
\item Independently, 
  \begin{equation*}
    \begin{split}
      \expp{X Y} &= \sum_{x,y \in \image X \times \image Y}{ xy P(X = x \cap Y = y)} \\
      &= \sum_{x,y \in \image X \times \image Y}{ xy P(X = x )P(Y = y)} \\
      &=\sum_{x \in \image X}{\sum_{y \in \image Y}{ xy P(X = x )P(Y = y)}} \\
      &=\sum_{x \in \image X}{xP(X=x)\sum_{y \in \image Y}{ y P(Y = y)}} \\
      &=\sum_{x \in \image X}{xP(X=x) \expp{Y} }  \\ 
      &=\expp{X} \expp{Y}% \sum_{x \in \image X}{xP(X=x) }  \\ 
    \end{split}
  \end{equation*}
\item Let $X$ be the random variable which is also the constant function $X(\omega) = a$ for any $\omega \in \Omega$. Then we have that
  \begin{equation*}
    \begin{split}
      \expp{X} & = \sum_{\omega\in \Omega}{X(\omega)P(\omega)} \\ & = \sum_{\omega\in \Omega}{a P(\omega)} = a \cdot 1 = a  
    \end{split}
  \end{equation*}
  \end{enumerate}
\end{proof}

\begin{example} Let $X$ be an indicator of event $A$, what are $\expp{X}$ and $\expp{X^{2}}$? Recall that $X(\omega) = 1$ only if $\omega \in A$ and $0$ otherwise, thus: 
  \begin{equation*}
    X^{k}(\omega) = \begin{cases}
      1^{k} = 1 & \omega \in A \\
      0^{k} = 0 & \text{ else }
    \end{cases} \Rightarrow X^{k}(\omega) = X(\omega)
  \end{equation*}
  Therefore, 
  \begin{equation*}
    \begin{split}
      \expp{X^{k}} = \sum_{\omega \in \Omega}{ X^{k}(\omega)  P(\omega)  } = \sum_{\omega \in \Omega}{ X(\omega)  P(\omega)  }=\expp{X} 
    \end{split}
  \end{equation*}
\end{example}
\begin{example}
  
Consider the experiment of throwing keys into cells again. What is the expected number of keys that fell into the same cell as the first key?  The indicator of the event $j$ and $1$ falling into the same cell is given by $\sum_{i}X_{i}^{1}X_{i}^{j}$ and it remains to sum over all the $j$'s. So:
  \marginnote[ Note 1: Despite the ease of computing the expectation, calculating the exact probability of $\sum_{i}\sum_{j}X_{i}^{1}X_{i}^{j} = L$ for some arbitrary $L$ is a difficult task.]{Note 1: Despite the ease of computing the expectation, calculating the exact probability of $\sum_{i}\sum_{j}X_{i}^{1}X_{i}^{j} = L$ for some arbitrary $L$ is a difficult task.}\begin{equation*}
    \begin{split}
      & \expp{ \sum_{i}\sum_{j}X_{i}^{1}X_{i}^{j}} = \sum_{i}\sum_{j}\expp{X_{i}^{1}X_{i}^{j}} \\  
      = &   \sum_{i}\sum_{j\neq 1}\expp{X_{i}^{1}}\expp{X_{i}^{j}} +  \overbrace{\sum_{i}\expp{X_{i}^{1}}}^{ j = 1} \\ 
      = & m \cdot (n-1) \frac{1}{m^{2}} + m\cdot \frac{1}{m} = \frac{n-1}{m} + 1 
    \end{split}
  \end{equation*}
\end{example}
\section{Running Time as a Random Variable.}
Randomness might appears in algoritmic context in two main cases, in the first the algorithm might behave randomly, means that it flips coins and decided what to do conditioning on the outcomes. In the second case, the input might distributed according to probability function. In both cases the result and running time of the algorithm are random variable. And it's interesting to ask what is the expected running time.

%For example, consider an array $A$ such any number of it is sample uniformly from $[0,1]$ which mean that probabiliy of $A_{i}$ to belong to segment $I \subset [0,1]$ is exactly: 
%\begin{equation*}
%  \begin{split}
%    P(A_{i} \in I) = |I|
%  \end{split}
%\end{equation*}
%The following algorithm takes advantage of sorting $A$. It separates the range $[0,1]$ into $n$ buckets $B_{1}..B_{n}$, where $B_{i}$ is associated with all the numbers in the range $[i/n, (i+1)/n)$. First, it inserts any element $A_{i}$ into the $B_{ \lfloor n A_{i} \rfloor} ]$ and then sorts each of the buckets separately (using some naive $\Theta(n^2)$-sort).
%

\begin{algorithm}
  \KwResult{returns the $k$ smallest element in \(A_1 ... A_n \in \mathbb{R}^n \)  }
\If{ left $=$ right} { 
  \Return $A_{\text{left}}$
  }
  pivot $\leftarrow$ select random pivot in [left, right]\\
  pivot $\leftarrow$ partition($A$, left, right, pivot) \\
  \If{ $k$ = pivot } {
    \Return $A_{k}$
  }
  \ElseIf{ $k < $  pivot  }{
  right $\leftarrow$ pivot - 1
  }
  \Else{
  left $\leftarrow$ pivot + 1\\
  $k \leftarrow k - $ pivot      

  }
  \Return call select($A$, left, right,  $k$)

  \caption{select($A$, left, right,  $k$)}
\end{algorithm}

Consider the first call for 'select', and denote by $X_{m}$ the indicator for picking on line (4) the index of the $m$ smallest number. Hence, the running time is    
\begin{equation*}
  \begin{split}
    T(n,k) &= c\cdot n + \sum_{m < k}{ X_{m} \cdot T(n-m, k -m)} \\ 
    & \ \ \ \ + X_{k} \cdot 1  + \sum_{m > k}{ X_{m} \cdot T(m, k)} \\ 
    & \le c\cdot n + 2c +  2c \sum_{m < k}{ \frac{n-m}{n} }  + 2c\sum_{m > k}{ \frac{m}{n}} \\
  & \le c\cdot n + +2c + (n-1)\cdot 2c\cdot \frac{1}{n} \cdot \max \{ k , n -  k - 1 \}\\
    & \le 2c \cdot n 
  \end{split}
\end{equation*}

%\begin{algorithm}
%    	let B[0 : n – 1] be a new array \\
%	\For{ $i \leftarrow [0, n – 1]$}{
%	   make $B_{i}$ an empty list
%       	}
%	\For{ $i \leftarrow [1, n]$}{
%	    insert $A_{i}$ into list $B_{ \lfloor n A_{i} \rfloor} ]$
%       	}
%	\For{ $i \leftarrow [0, n – 1]$}{
%	    sort list $B_{i}$
%       	}
%	concatenate the lists $B_{0}, B_{1}, .. , B_{n – 1}$ together and\\
%	return the concatenated lists
%\caption{bucket-sort($A$, $n$)}
%  \end{algorithm} 
%  Denote by $X_{i} : [n] \rightarrow [n]$ the random variable that counts the number of elements fallen in the $i$th bucket, and by $X_{i}^{j}$ the indicator that $A_{i}\in B_{i}$, So $P(X_{i}^{j}=1) = P(A_{i} \in B_{j}) = |[j/n, (j+1)/n)|=1/n$. The expectation of the sorting running time is:
%  \begin{equation*}
%    \begin{split}
%    \expp{T} &= \expp{  \text{ Inserting into buckets  }   +   \sum_{i} { \text{Sorting $i$th bucket  } }} \\ 
%    & = \expp{ \Theta(n) +   \sum_{i} { X_{i}^{2}  }} = \Theta(n) +  \sum_{i}{ \expp{X_{i}^{2}} }  \\
%  \expp{X_{i}^{2}} &= \expp{\left( \sum X_{i}^{j} \right)^{2}} = \expp{\sum_{j,j^{\prime}} X_{i}^{j} X_{i}^{j^{\prime}} } =  \sum_{j, j^{\prime}} \expp{X_{i}^{j} X_{i}^{j^{\prime}}} \\ 
%  & = \sum_{j \neq j^{\prime}} \expp{X_{i}^{j} X_{i}^{j^{\prime}}} + \sum_{j} \expp{X_{i}^{j} X_{i}^{j}} \\
%    & =  \sum_{j \neq j^{\prime}} \expp{X_{i}^{j} X_{i}^{j^{\prime}}} + \sum_{j} \expp{X_{i}^{j}}  \\
%        & = 2 { n \choose 2  } \left( \frac{1}{n} \right)^{2} +  n\cdot \frac{1}{n} \\ 
%        & = \frac{n-1}{n} + 1  = 2 - \frac{1}{n} \Rightarrow \expp{T} = \Theta(n) + n\left( 2 - \frac{1}{n} \right) = \Theta(n)
%    \end{split}
%  \end{equation*}

\input{../texlib/tail}


